{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('new_file.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  Cybersecurity provider ZingBox has announced t...   \n",
       "1  Enterprise data centre provider Aegis Data arg...   \n",
       "2  From Domino’s Pizza, to Uber, to Bank of Ameri...   \n",
       "3  Organisations investing in artificial intellig...   \n",
       "4  Tencent’s cloud computing services will be bee...   \n",
       "\n",
       "                  Industry1          Industry2  \n",
       "0  Public and Social sector  Consumer Products  \n",
       "1         Consumer Products             Energy  \n",
       "2                     Media            Telecom  \n",
       "3  Public and Social sector            Finance  \n",
       "4         Consumer Products            Telecom  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Industry1</th>\n      <th>Industry2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cybersecurity provider ZingBox has announced t...</td>\n      <td>Public and Social sector</td>\n      <td>Consumer Products</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Enterprise data centre provider Aegis Data arg...</td>\n      <td>Consumer Products</td>\n      <td>Energy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From Domino’s Pizza, to Uber, to Bank of Ameri...</td>\n      <td>Media</td>\n      <td>Telecom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Organisations investing in artificial intellig...</td>\n      <td>Public and Social sector</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tencent’s cloud computing services will be bee...</td>\n      <td>Consumer Products</td>\n      <td>Telecom</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 text  \\\n",
       "0   Cybersecurity provider ZingBox has announced t...   \n",
       "1   Enterprise data centre provider Aegis Data arg...   \n",
       "2   From Domino’s Pizza, to Uber, to Bank of Ameri...   \n",
       "3   Organisations investing in artificial intellig...   \n",
       "4   Tencent’s cloud computing services will be bee...   \n",
       "5   US-based Bonsai is set to engage enterprises a...   \n",
       "6   The Kentucky Derby, one of the three races whi...   \n",
       "7   A new survey commissioned by the UC EXPO event...   \n",
       "8   Gartner has given a tentative guideline of 202...   \n",
       "9   Cisco has announced its intent to acquire Mind...   \n",
       "10  The Leverhulme Centre for the Future of Intell...   \n",
       "11  Cray has launched two new CS-Storm accelerated...   \n",
       "12  UNICEF has announced it has joined Partnership...   \n",
       "13  TCS Digital Software & Solutions Group, part o...   \n",
       "14  Australia-based Cylance has announced the gene...   \n",
       "15  People.ai has received $7 million in Series A ...   \n",
       "16  Artificial intelligence (AI) and deep learning...   \n",
       "17  San Francisco-based crowdsourcing firm CrowdFl...   \n",
       "18  CognitiveScale has announced it has raised an ...   \n",
       "19  A new report from the IEEE has shed light on w...   \n",
       "\n",
       "                   Industry1                 Industry2  \n",
       "0   Public and Social sector         Consumer Products  \n",
       "1          Consumer Products                    Energy  \n",
       "2                      Media                   Telecom  \n",
       "3   Public and Social sector                   Finance  \n",
       "4          Consumer Products                   Telecom  \n",
       "5      Transport & Logistics         Consumer Products  \n",
       "6                 automative               Agriculture  \n",
       "7   Public and Social sector                   Finance  \n",
       "8          Consumer Products  Public and Social sector  \n",
       "9                      Media                   Telecom  \n",
       "10  Public and Social sector                   Finance  \n",
       "11         Consumer Products                   Telecom  \n",
       "12  Public and Social sector                   Finance  \n",
       "13                    Energy     Transport & Logistics  \n",
       "14  Public and Social sector     Transport & Logistics  \n",
       "15         Consumer Products                   Finance  \n",
       "16               Health Care           Pharmaceuticals  \n",
       "17         Consumer Products  Public and Social sector  \n",
       "18  Public and Social sector         Consumer Products  \n",
       "19  Public and Social sector               Health Care  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Industry1</th>\n      <th>Industry2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cybersecurity provider ZingBox has announced t...</td>\n      <td>Public and Social sector</td>\n      <td>Consumer Products</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Enterprise data centre provider Aegis Data arg...</td>\n      <td>Consumer Products</td>\n      <td>Energy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From Domino’s Pizza, to Uber, to Bank of Ameri...</td>\n      <td>Media</td>\n      <td>Telecom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Organisations investing in artificial intellig...</td>\n      <td>Public and Social sector</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tencent’s cloud computing services will be bee...</td>\n      <td>Consumer Products</td>\n      <td>Telecom</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>US-based Bonsai is set to engage enterprises a...</td>\n      <td>Transport &amp; Logistics</td>\n      <td>Consumer Products</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The Kentucky Derby, one of the three races whi...</td>\n      <td>automative</td>\n      <td>Agriculture</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A new survey commissioned by the UC EXPO event...</td>\n      <td>Public and Social sector</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Gartner has given a tentative guideline of 202...</td>\n      <td>Consumer Products</td>\n      <td>Public and Social sector</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Cisco has announced its intent to acquire Mind...</td>\n      <td>Media</td>\n      <td>Telecom</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The Leverhulme Centre for the Future of Intell...</td>\n      <td>Public and Social sector</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Cray has launched two new CS-Storm accelerated...</td>\n      <td>Consumer Products</td>\n      <td>Telecom</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>UNICEF has announced it has joined Partnership...</td>\n      <td>Public and Social sector</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>TCS Digital Software &amp; Solutions Group, part o...</td>\n      <td>Energy</td>\n      <td>Transport &amp; Logistics</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Australia-based Cylance has announced the gene...</td>\n      <td>Public and Social sector</td>\n      <td>Transport &amp; Logistics</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>People.ai has received $7 million in Series A ...</td>\n      <td>Consumer Products</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Artificial intelligence (AI) and deep learning...</td>\n      <td>Health Care</td>\n      <td>Pharmaceuticals</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>San Francisco-based crowdsourcing firm CrowdFl...</td>\n      <td>Consumer Products</td>\n      <td>Public and Social sector</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>CognitiveScale has announced it has raised an ...</td>\n      <td>Public and Social sector</td>\n      <td>Consumer Products</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>A new report from the IEEE has shed light on w...</td>\n      <td>Public and Social sector</td>\n      <td>Health Care</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text']\n",
    "y = df.drop('text',axis=1)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(ytrain[['Industry1','Industry2']].values)\n",
    "test_labels = mlb.fit_transform(ytest[['Industry1','Industry2']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Agriculture', 'Consumer Products', 'Energy', 'Finance',\n",
       "       'Health Care', 'Manufacturing', 'Media', 'Pharmaceuticals',\n",
       "       'Public and Social sector', 'Telecom', 'Transport & Logistics',\n",
       "       'automative'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "mlb.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "english_stops = set(STOPWORDS)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def tokenize_lemma_stopwords(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    tokens = nltk.tokenize.word_tokenize(text.lower()) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if t.isalpha()] # keep strings with only alphabets\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [t for t in tokens if t not in english_stops] # remove stopwords\n",
    "    cleanedText = \" \".join(tokens)\n",
    "    return cleanedText\n",
    "\n",
    "def dataCleaning(df):\n",
    "    data = df.copy()\n",
    "    data = data.apply(tokenize_lemma_stopwords)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTrainData = dataCleaning(xtrain)\n",
    "cleanedTestData = dataCleaning(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorised_train_documents = vectorizer.fit_transform(cleanedTrainData)\n",
    "vectorised_test_documents = vectorizer.transform(cleanedTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vec.pickle','wb') as f1 :\n",
    "    pickle.dump(vectorizer,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "ModelsPerformance = {}\n",
    "\n",
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + modelName + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "    ModelsPerformance[modelName] = micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------SVC Sq. Hinge Loss Model Metrics-----\nAccuracy: 0.3190\nHamming Loss: 0.0920\nPrecision:\n  - Macro: 0.8128\n  - Micro: 0.8120\nRecall:\n  - Macro: 0.4481\n  - Micro: 0.5828\nF1-measure:\n  - Macro: 0.5575\n  - Micro: 0.6786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "svmClassifier = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svmClassifier.fit(vectorised_train_documents, train_labels)\n",
    "\n",
    "svmPreds = svmClassifier.predict(vectorised_test_documents)\n",
    "metricsReport(\"SVC Sq. Hinge Loss\", test_labels, svmPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------Power Set SVC Model Metrics-----\nAccuracy: 0.4724\nHamming Loss: 0.1048\nPrecision:\n  - Macro: 0.7078\n  - Micro: 0.6856\nRecall:\n  - Macro: 0.5795\n  - Micro: 0.6856\nF1-measure:\n  - Macro: 0.6118\n  - Micro: 0.6856\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "powerSetSVC = LabelPowerset(LinearSVC())\n",
    "powerSetSVC.fit(vectorised_train_documents, train_labels)\n",
    "\n",
    "powerSetSVCPreds = powerSetSVC.predict(vectorised_test_documents)\n",
    "metricsReport(\"Power Set SVC\", test_labels, powerSetSVCPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerSetSVC.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('clf.pickle','wb') as f :\n",
    "    pickle.dump(powerSetSVC,f)"
   ]
  },
  {
   "source": [
    "## Predicting Single Entry"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 1)\t1\n  (0, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "with open(\"clf.pickle\", 'rb') as model_file :\n",
    "    model = pickle.load(model_file)\n",
    "cv = CountVectorizer()\n",
    "\n",
    "text_processed = tokenize_lemma_stopwords(df['text'][0])\n",
    "new_corpus = [text_processed]\n",
    "new_X_test = vectorizer.transform(new_corpus).toarray()\n",
    "\n",
    "#text_vectorised = vectorizer.fit_transform()\n",
    "pred = model.predict(new_X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "pred1 = lil_matrix.toarray(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_dict = {'Agriculture': 4,\n",
    "     'Consumer Products': 2,\n",
    "     'Energy': 5,\n",
    "     'Finance': 3,\n",
    "     'Health Care': 6,\n",
    "     'Manufacturing': 1,\n",
    "     'Media': 9,\n",
    "     'Pharmaceuticals': 7,\n",
    "     'Public and Social sector': 8,\n",
    "     'Telecom': 10,\n",
    "     'Transport & Logistics': 11,\n",
    "     'automative': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.where(pred1 == 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = list(industry_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Consumer Products\n"
     ]
    }
   ],
   "source": [
    "industry_type = key_list[positions[0]]\n",
    "print(industry_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_industries = []\n",
    "predicted_industries.append(key_list[positions[0]])\n",
    "predicted_industries.append(key_list[positions[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Consumer Products', 'Public and Social sector']"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "predicted_industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import lil_matrix\n",
    "import pickle\n",
    "\n",
    "#text = df['text'][0]\n",
    "\n",
    "def prediction(text) :\n",
    "    \n",
    "with open(\"clf.pickle\", 'rb') as model_file :\n",
    "    model = pickle.load(model_file)\n",
    "with open(\"vec.pickle\", 'rb') as vec_file :\n",
    "    vectorizer = pickle.load(vec_file)\n",
    "\n",
    "text_processed = tokenize_lemma_stopwords(text)\n",
    "new_corpus = [text_processed]\n",
    "new_X_test = vectorizer.transform(new_corpus).toarray()\n",
    "\n",
    "pred = model.predict(new_X_test)\n",
    "pred1 = lil_matrix.toarray(pred)\n",
    "\n",
    "industry_dict = {'Agriculture': 4,\n",
    "     'Consumer Products': 2,\n",
    "     'Energy': 5,\n",
    "     'Finance': 3,\n",
    "     'Health Care': 6,\n",
    "     'Manufacturing': 1,\n",
    "     'Media': 9,\n",
    "     'Pharmaceuticals': 7,\n",
    "     'Public and Social sector': 8,\n",
    "     'Telecom': 10,\n",
    "     'Transport & Logistics': 11,\n",
    "     'automative': 0}\n",
    "key_list = list(industry_dict.keys())\n",
    "positions = np.where(pred1 == 1)[1]\n",
    "predicted_industries = []\n",
    "predicted_industries.append(key_list[positions[0]])\n",
    "predicted_industries.append(key_list[positions[1]])\n",
    "\n",
    "return predicted_industries\n"
   ]
  }
 ]
}